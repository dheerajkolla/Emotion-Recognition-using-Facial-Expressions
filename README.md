# Emotion-Recognition-using-Facial-Expressions

This project focuses on facial emotion recognition using deep learning models, including CNN, ResNet, MobileNet, and EfficientNet, on the FER2013 dataset. The dataset consists of grayscale facial images labeled with seven emotions: Angry, Disgust, Fear, Happy, Sad, Surprise, and Neutral. The project involves extensive experimentation with different model architectures to understand their performance in emotion classification. ResNet emerged as the most accurate model, showcasing its ability to capture complex features in facial expressions. CNN, EfficientNet, and MobileNet also demonstrated competitive performance. In addition to model training and evaluation, the project extends to real-time applications. The trained ResNet model is saved and integrated with a webcam, enabling real-time facial emotion recognition. This integration enhances the practicality of the project, making it applicable for various interactive systems and applications. The report details the dataset, model architectures, training processes, and comparative results. The success of ResNet in achieving the highest accuracy underscores its effectiveness in facial emotion recognition. The real-time integration further demonstrates the project's potential for real-world applications, contributing to the field of computer vision and human-computer interaction.

